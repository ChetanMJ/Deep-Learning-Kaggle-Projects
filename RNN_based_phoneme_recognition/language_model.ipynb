{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pFvgJbAu50m8"
   },
   "source": [
    "# Shakespeare Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1570798926181,
     "user": {
      "displayName": "Kangrui Ruan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBkIxCY2kVNxL_2U5DUtjBlXGoYrvft9Xw4htwX=s64",
      "userId": "10858235878974059696"
     },
     "user_tz": 240
    },
    "id": "mcIAFm9g50m9",
    "outputId": "fb5c9a27-0b83-4d51-c1fb-5b64a5841abf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import shakespeare_data as sh\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gN0cVBCS50nB"
   },
   "source": [
    "## Fixed length input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1587,
     "status": "ok",
     "timestamp": 1570798927487,
     "user": {
      "displayName": "Kangrui Ruan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBkIxCY2kVNxL_2U5DUtjBlXGoYrvft9Xw4htwX=s64",
      "userId": "10858235878974059696"
     },
     "user_tz": 240
    },
    "id": "uFhKFJEN50nB",
    "outputId": "bcd8c5e9-8975-4065-879c-a5cde014c3b6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 203 characters...Last 50 characters\n",
      "1609\n",
      " THE SONNETS\n",
      " by William Shakespeare\n",
      "                      1\n",
      "   From fairest creatures we desire increase,\n",
      "   That thereby beauty's rose might never die,\n",
      "   But as the riper should by time decease,\n",
      "...,\n",
      "   And new pervert a reconciled maid.'\n",
      " THE END\n",
      "\n",
      "Total character count: 5551930\n",
      "Unique character count: 84\n",
      "\n",
      "shakespeare_array.shape: (5551930,)\n",
      "\n",
      "First 17 characters as indices [12 17 11 20  0  1 45 33 30  1 44 40 39 39 30 45 44]\n",
      "First 17 characters as characters: ['1', '6', '0', '9', '\\n', ' ', 'T', 'H', 'E', ' ', 'S', 'O', 'N', 'N', 'E', 'T', 'S']\n",
      "First 17 character indices as text:\n",
      " 1609\n",
      " THE SONNETS\n"
     ]
    }
   ],
   "source": [
    "# Data - refer to shakespeare_data.py for details\n",
    "corpus = sh.read_corpus()\n",
    "print(\"First 203 characters...Last 50 characters\")\n",
    "print(\"{}...{}\".format(corpus[:203], corpus[-50:]))\n",
    "print(\"Total character count: {}\".format(len(corpus)))\n",
    "chars, charmap = sh.get_charmap(corpus)\n",
    "charcount = len(chars)\n",
    "print(\"Unique character count: {}\\n\".format(len(chars)))\n",
    "shakespeare_array = sh.map_corpus(corpus, charmap)\n",
    "print(\"shakespeare_array.shape: {}\\n\".format(shakespeare_array.shape))\n",
    "small_example = shakespeare_array[:17]\n",
    "print(\"First 17 characters as indices\", small_example)\n",
    "print(\"First 17 characters as characters:\", [chars[c] for c in small_example])\n",
    "print(\"First 17 character indices as text:\\n\", sh.to_text(small_example,chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBcpz6iD50nD"
   },
   "outputs": [],
   "source": [
    "# Dataset class. Transform raw text into a set of sequences of fixed length, and extracts inputs and targets\n",
    "class TextDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,text, seq_len = 200):\n",
    "        n_seq = len(text) // seq_len\n",
    "        text = text[:n_seq * seq_len]\n",
    "        self.data = torch.tensor(text).view(-1,seq_len)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        txt = self.data[i]\n",
    "        \n",
    "        # labels are the input sequence shifted by 1\n",
    "        return txt[:-1],txt[1:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "# Collate function. Transform a list of sequences into a batch. Passed as an argument to the DataLoader.\n",
    "# Returns data of the format seq_len x batch_size\n",
    "def collate(seq_list):\n",
    "    inputs = torch.cat([s[0].unsqueeze(1) for s in seq_list],dim=1)\n",
    "    targets = torch.cat([s[1].unsqueeze(1) for s in seq_list],dim=1)\n",
    "    return inputs,targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHb5PHQs50nF"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class CharLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size,embed_size,hidden_size, nlayers):\n",
    "        super(CharLanguageModel,self).__init__()\n",
    "        self.vocab_size=vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nlayers=nlayers\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size) # Embedding layer\n",
    "        self.rnn = nn.LSTM(input_size = embed_size,hidden_size=hidden_size,num_layers=nlayers) # Recurrent network\n",
    "        # You can also try GRUs instead of LSTMs.\n",
    "        \n",
    "        self.scoring = nn.Linear(hidden_size,vocab_size) # Projection layer\n",
    "        \n",
    "    def forward(self,seq_batch): #L x N\n",
    "        # returns 3D logits\n",
    "        batch_size = seq_batch.size(1)\n",
    "        embed = self.embedding(seq_batch) #L x N x E\n",
    "        hidden = None\n",
    "        output_lstm,hidden = self.rnn(embed,hidden) #L x N x H\n",
    "        output_lstm_flatten = output_lstm.view(-1,self.hidden_size) #(L*N) x H\n",
    "        output_flatten = self.scoring(output_lstm_flatten) #(L*N) x V\n",
    "        return output_flatten.view(-1,batch_size,self.vocab_size)\n",
    "    \n",
    "    def generate(self,seq, n_words): # L x V\n",
    "        # performs greedy search to extract and return words (one sequence).\n",
    "        generated_words = []\n",
    "        embed = self.embedding(seq).unsqueeze(1) # L x 1 x E\n",
    "        hidden = None\n",
    "        output_lstm, hidden = self.rnn(embed,hidden) # L x 1 x H\n",
    "        output = output_lstm[-1] # 1 x H\n",
    "        scores = self.scoring(output) # 1 x V\n",
    "        _,current_word = torch.max(scores,dim=1) # 1 x 1\n",
    "        generated_words.append(current_word)\n",
    "        if n_words > 1:\n",
    "            for i in range(n_words-1):\n",
    "                embed = self.embedding(current_word).unsqueeze(0) # 1 x 1 x E\n",
    "                output_lstm, hidden = self.rnn(embed,hidden) # 1 x 1 x H\n",
    "                output = output_lstm[0] # 1 x H\n",
    "                scores = self.scoring(output) # V\n",
    "                _,current_word = torch.max(scores,dim=1) # 1\n",
    "                generated_words.append(current_word)\n",
    "        return torch.cat(generated_words,dim=0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([199, 64])\n",
      "torch.Size([199, 64])\n",
      "torch.Size([12736])\n",
      "torch.Size([199, 64])\n",
      "torch.Size([199, 64])\n",
      "torch.Size([12736])\n",
      "torch.Size([199, 64])\n",
      "torch.Size([199, 64])\n",
      "torch.Size([12736])\n",
      "torch.Size([199, 64])\n",
      "torch.Size([199, 64])\n",
      "torch.Size([12736])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (inputs,targets) in enumerate(train_loader):\n",
    "     print(inputs.size())\n",
    "     print(targets.size())\n",
    "     tg = targets.view(-1)\n",
    "     print(tg.size())\n",
    "        \n",
    "     if batch_idx  > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QRxGHF6E50nH"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, train_loader, val_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(DEVICE)\n",
    "    before = time.time()\n",
    "    print(\"training\", len(train_loader), \"number of batches\")\n",
    "    for batch_idx, (inputs,targets) in enumerate(train_loader):\n",
    "        if batch_idx == 0:\n",
    "            first_time = time.time()\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        outputs = model(inputs) # 3D\n",
    "        loss = criterion(outputs.view(-1,outputs.size(2)),targets.view(-1)) # Loss of the flattened outputs\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            print(\"Time elapsed\", time.time() - first_time)\n",
    "            \n",
    "        if batch_idx % 100 == 0 and batch_idx != 0:\n",
    "            after = time.time()\n",
    "            print(\"Time: \", after - before)\n",
    "            print(\"Loss per word: \", loss.item() / batch_idx)\n",
    "            print(\"Perplexity: \", np.exp(loss.item() / batch_idx))\n",
    "            after = before\n",
    "    \n",
    "    val_loss = 0\n",
    "    batch_id=0\n",
    "    for inputs,targets in val_loader:\n",
    "        batch_id+=1\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.view(-1,outputs.size(2)),targets.view(-1))\n",
    "        val_loss+=loss.item()\n",
    "    val_lpw = val_loss / batch_id\n",
    "    print(\"\\nValidation loss per word:\",val_lpw)\n",
    "    print(\"Validation perplexity :\",np.exp(val_lpw),\"\\n\")\n",
    "    return val_lpw\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNHa3FAU50nI"
   },
   "outputs": [],
   "source": [
    "model = CharLanguageModel(charcount,256,256,3)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001, weight_decay=1e-6)\n",
    "split = 5000000\n",
    "train_dataset = TextDataset(shakespeare_array[:split])\n",
    "val_dataset = TextDataset(shakespeare_array[split:])\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64, collate_fn = collate)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=64, collate_fn = collate, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "VVROzTRT50nK",
    "outputId": "298367fc-5751-435f-9b4f-b87a8eed1a0a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 391 number of batches\n",
      "Time elapsed 3.9039366245269775\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    train_epoch(model, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xd-bklsK50nM"
   },
   "outputs": [],
   "source": [
    "def generate(model, seed,nwords):\n",
    "    seq = sh.map_corpus(seed, charmap)\n",
    "    seq = torch.tensor(seq).to(DEVICE)\n",
    "    out = model.generate(seq,nwords)\n",
    "    return sh.to_text(out.cpu().detach().numpy(),chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-Sp34eF50nN"
   },
   "outputs": [],
   "source": [
    "print(generate(model, \"To be, or not to be, that is the q\",8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WPIhJur50nP"
   },
   "outputs": [],
   "source": [
    "print(generate(model, \"Richard \", 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OITobxJ_50nS"
   },
   "source": [
    "## Packed sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZshan9w50nS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 17 11 20  0]\n",
      "[ 1 45 33 30  1 44 40 39 39 30 45 44  0]\n",
      "[ 1 57 80  1 48 64 67 67 64 56 68  1 44 63 56 66 60 74 71 60 56 73 60  0]\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0]\n",
      "[ 1  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60\n",
      " 74  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0]\n",
      "[ 1  1  1 45 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74\n",
      "  1 73 70 74 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0]\n",
      "[ 1  1  1 27 76 75  1 56 74  1 75 63 60  1 73 64 71 60 73  1 74 63 70 76\n",
      " 67 59  1 57 80  1 75 64 68 60  1 59 60 58 60 56 74 60  8  0]\n",
      "[ 1  1  1 33 64 74  1 75 60 69 59 60 73  1 63 60 64 73  1 68 64 62 63 75\n",
      "  1 57 60 56 73  1 63 64 74  1 68 60 68 70 73 80 21  0]\n",
      "[ 1  1  1 27 76 75  1 75 63 70 76  1 58 70 69 75 73 56 58 75 60 59  1 75\n",
      " 70  1 75 63 64 69 60  1 70 78 69  1 57 73 64 62 63 75  1 60 80 60 74  8\n",
      "  0]\n",
      "[ 1  1  1 31 60 60 59  5 74 75  1 75 63 80  1 67 64 62 63 75  5 74  1 61\n",
      " 67 56 68 60  1 78 64 75 63  1 74 60 67 61  9 74 76 57 74 75 56 69 75 64\n",
      " 56 67  1 61 76 60 67  8  0]\n",
      "114638\n"
     ]
    }
   ],
   "source": [
    "stop_character = charmap['\\n']\n",
    "space_character = charmap[\" \"]\n",
    "lines = np.split(shakespeare_array, np.where(shakespeare_array == stop_character)[0]+1) # split the data in lines\n",
    "shakespeare_lines = []\n",
    "for s in lines:\n",
    "    s_trimmed = np.trim_zeros(s-space_character)+space_character # remove space-only lines\n",
    "    if len(s_trimmed)>1:\n",
    "        shakespeare_lines.append(s)\n",
    "for i in range(10):\n",
    "    ##print(sh.to_text(shakespeare_lines[i],chars))\n",
    "    print(shakespeare_lines[i])\n",
    "print(len(shakespeare_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1106,)\n",
      "(440, 40)\n",
      "FLAT\n",
      "torch.Size([693218, 40])\n",
      "torch.Size([693218, 40])\n",
      "torch.Size([1106, 193])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import *\n",
    "\n",
    "path_train = 'wsj0_dev.npy'\n",
    "path_train_lables = 'wsj0_dev_merged_labels.npy'\n",
    "path_test = 'wsj0_test.npy'\n",
    "\n",
    "train_data = np.load(path_train, allow_pickle = True, encoding='bytes')\n",
    "print(train_data.shape)\n",
    "print(train_data[0].shape)\n",
    "\n",
    "\n",
    "\n",
    "train_labels = np.load(path_train_lables, allow_pickle = True, encoding= 'bytes')\n",
    "test = np.load(path_test, allow_pickle = True, encoding='bytes')\n",
    "\n",
    "\n",
    "timeframe_length = []\n",
    "train_data_list = []\n",
    "\n",
    "for i in range(train_data.shape[0]):\n",
    "    tlen = train_data[i].shape[0]\n",
    "    timeframe_length.append(tlen*40)\n",
    "    train_data_list.append(torch.DoubleTensor(train_data[i]))\n",
    "    \n",
    "print(\"FLAT\")\n",
    "train_data_flat = torch.cat(train_data_list)\n",
    "print(train_data_flat.size())\n",
    "max_timeframe_length = max(timeframe_length)\n",
    "timeframe_length = torch.LongTensor(timeframe_length)\n",
    "\n",
    "\n",
    "\n",
    "output_length = []\n",
    "train_labels_flat = []\n",
    "for i in range(train_labels.shape[0]):\n",
    "    output_length.append(train_labels[i].shape[0])\n",
    "    train_labels_flat.append(torch.LongTensor(train_labels[i]))\n",
    "\n",
    "##train_labels_flat = torch.LongTensor(train_labels_flat)\n",
    "output_length = torch.LongTensor(output_length)\n",
    "max_output_length = max(output_length)\n",
    "\n",
    "\n",
    "##X1 = pad_sequence(train_data_flat)\n",
    "train_labels_flat = pad_sequence(train_labels_flat,batch_first=True )\n",
    "\n",
    "print(train_data_flat.size())\n",
    "\n",
    "print(train_labels_flat.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1UckTXZ50nU"
   },
   "outputs": [],
   "source": [
    "class LinesDataset(Dataset):\n",
    "    def __init__(self,lines):\n",
    "        self.lines=[torch.tensor(l) for l in lines]\n",
    "    def __getitem__(self,i):\n",
    "        line = self.lines[i]\n",
    "        return line[:-1].to(DEVICE),line[1:].to(DEVICE)\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "# collate fn lets you control the return value of each batch\n",
    "# for packed_seqs, you want to return your data sorted by length\n",
    "def collate_lines(seq_list):\n",
    "    ##print(len(seq_list))\n",
    "    inputs,targets = zip(*seq_list)\n",
    "    lens = [len(seq) for seq in inputs]\n",
    "    seq_order = sorted(range(len(lens)), key=lens.__getitem__, reverse=True)\n",
    "    ##print(seq_order)\n",
    "    inputs = [inputs[i] for i in seq_order]\n",
    "    targets = [targets[i] for i in seq_order]\n",
    "    return inputs,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.LinesDataset object at 0x7fa1ec97f668>\n",
      "torch.Size([70])\n",
      "Batchsize\n",
      "64\n",
      "lens\n",
      "[70, 70, 69, 68, 68, 67, 66, 65, 64, 62, 60, 58, 57, 56, 55, 55, 54, 51, 51, 51, 51, 51, 50, 50, 49, 49, 48, 48, 48, 48, 48, 48, 47, 47, 47, 47, 47, 47, 47, 46, 45, 45, 45, 45, 45, 44, 43, 42, 41, 41, 41, 41, 41, 40, 39, 34, 32, 32, 31, 30, 27, 27, 20, 17]\n",
      "3068\n",
      "64\n",
      "torch.Size([70])\n",
      "seq_concat\n",
      "torch.Size([3068])\n",
      "tensor([ 1,  1,  1,  1,  1, 26, 69, 59,  1, 74, 68, 70, 75, 60,  1, 63, 64, 68,\n",
      "         8,  1], device='cuda:0')\n",
      "Embedd output\n",
      "torch.Size([3068, 256])\n",
      "tensor([-2.0149e+00, -6.0361e-01, -1.1960e+00, -2.2865e+00, -4.4859e-01,\n",
      "         7.6630e-01, -8.6979e-02,  2.3454e+00,  1.0890e+00, -3.9619e-01,\n",
      "        -7.1854e-01, -1.1675e+00,  9.4324e-01, -9.8904e-01,  2.3972e-02,\n",
      "         4.3202e-01,  1.1914e+00, -2.0167e+00,  1.3723e+00,  1.7466e-01,\n",
      "         3.8195e-01,  1.5554e+00,  1.3900e+00, -7.5800e-01, -1.0323e+00,\n",
      "        -1.6727e+00,  4.4193e-01, -5.5694e-01,  3.9919e-02, -9.7039e-02,\n",
      "         1.7457e-01, -1.6456e-01, -8.7709e-01, -2.3446e-01,  6.2831e-01,\n",
      "         1.0285e+00,  8.3067e-01,  6.2193e-01, -1.1403e+00, -2.4019e-02,\n",
      "         3.6901e-01,  2.6275e-01,  3.5265e-01,  2.1630e-01,  9.0341e-01,\n",
      "         8.8725e-01,  3.2058e-01, -7.1211e-01,  2.2954e+00,  2.6774e-02,\n",
      "        -2.2447e+00, -1.1399e+00,  7.6512e-01,  1.8569e+00,  1.2089e-01,\n",
      "         7.5122e-01, -9.3958e-01,  7.1224e-01, -1.5108e+00,  1.1801e+00,\n",
      "        -1.8316e+00,  1.5403e+00, -1.5066e+00,  5.2591e-01,  2.1435e+00,\n",
      "        -9.2790e-01, -3.0005e-02,  2.9634e-01, -1.1044e+00, -9.4780e-01,\n",
      "         1.0105e+00, -2.8461e+00,  9.0101e-02, -1.1082e+00,  3.6808e-01,\n",
      "         1.4697e+00, -3.6195e-02, -6.9149e-01,  2.2569e-01, -3.2174e-01,\n",
      "        -1.8702e-01, -1.3632e+00,  7.5785e-01, -9.1680e-01,  1.3965e+00,\n",
      "        -6.1125e-01,  8.3012e-01, -4.8949e-01,  6.4788e-01, -1.5009e-01,\n",
      "         2.2682e-01,  1.2417e-01, -8.5994e-01,  6.6468e-01, -1.4859e-01,\n",
      "         1.5469e+00,  9.2002e-01,  2.3920e+00, -1.8318e-01, -2.3217e-01,\n",
      "        -5.5603e-01, -1.3832e+00, -4.5281e-01,  1.6014e+00, -2.7283e-01,\n",
      "        -5.1491e-01, -2.3016e-01,  1.6936e+00, -1.2845e+00, -9.2509e-01,\n",
      "        -2.2107e-01,  1.2942e+00, -5.2536e-01, -1.3186e+00, -1.5210e+00,\n",
      "         1.3008e+00,  1.6033e-01, -5.9077e-01, -1.4646e-01, -1.2308e-01,\n",
      "        -1.7604e+00,  1.1102e+00,  1.2086e+00, -1.1981e+00,  1.2279e+00,\n",
      "        -1.0074e+00, -2.1430e+00,  1.2831e+00, -7.1660e-01, -4.8087e-01,\n",
      "         1.9538e+00,  1.9392e-01, -1.4361e-01, -8.7462e-01, -2.1184e-01,\n",
      "        -1.7307e+00,  8.5380e-01, -6.1095e-01,  1.7459e+00,  1.2664e+00,\n",
      "        -9.8319e-01, -1.2156e-01,  1.7389e-02, -1.5421e-01, -2.7973e-01,\n",
      "        -6.6346e-01, -2.3316e+00, -3.5619e-01,  8.2130e-01, -3.3915e-01,\n",
      "        -1.2736e+00,  8.3157e-01,  3.6249e-02,  1.2710e+00, -1.0853e+00,\n",
      "         9.3227e-01, -1.5071e+00,  8.2602e-01, -7.5044e-01,  7.9976e-01,\n",
      "        -5.5459e-01,  1.2416e+00, -8.8010e-01, -1.3623e-01, -1.3494e+00,\n",
      "        -9.5741e-01, -1.7106e+00, -1.5598e+00, -2.2177e-01, -1.7944e+00,\n",
      "        -8.6183e-01,  4.5885e-01,  1.2262e+00,  9.0597e-01,  6.4744e-01,\n",
      "        -9.2182e-01, -1.0907e+00,  5.8810e-01,  1.8058e-01, -1.5875e+00,\n",
      "         1.9433e+00,  1.2445e+00, -1.1115e+00,  1.2212e+00,  4.4815e-02,\n",
      "         4.6603e-01,  1.6024e-01,  1.5793e+00,  1.2924e+00,  1.7668e+00,\n",
      "        -1.3111e+00, -1.5918e+00,  6.9572e-01, -9.1478e-02, -1.0374e+00,\n",
      "         1.6585e+00,  8.0375e-01, -4.2236e-01, -2.2884e+00,  2.2564e+00,\n",
      "         1.4398e+00,  1.3968e+00,  1.6752e+00, -5.9030e-02,  1.4620e+00,\n",
      "         1.9537e+00, -5.9194e-01,  5.0903e-01, -1.6322e+00,  1.2806e+00,\n",
      "         7.9420e-01, -1.4277e+00,  1.0079e+00,  3.6794e-02, -1.8567e-01,\n",
      "        -3.2979e-01,  7.8281e-01, -1.3028e+00,  2.3227e-01,  6.9078e-01,\n",
      "        -6.6106e-01, -6.9559e-01,  1.0006e-01, -1.8608e+00,  1.0076e+00,\n",
      "         2.4342e-01,  1.0393e+00, -1.6966e-01,  6.6070e-01,  4.6056e-01,\n",
      "         1.7137e+00,  2.7296e-03, -1.1145e+00, -2.3437e-01, -1.5191e+00,\n",
      "        -2.4967e-01,  1.5529e-01, -5.8548e-01, -2.0581e+00,  1.1170e+00,\n",
      "         1.5967e+00,  1.6671e-01, -7.4083e-01,  2.9960e-01,  1.4641e+00,\n",
      "         7.1391e-01,  3.9289e-01,  7.2375e-01, -2.6147e-01, -1.1694e+00,\n",
      "         1.4020e+00,  3.4907e-01,  8.1614e-01, -1.4554e+00,  8.6820e-01,\n",
      "        -2.1470e-02], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Embedd List\n",
      "torch.Size([3068, 256])\n",
      "64\n",
      "torch.Size([70, 256])\n",
      "Packed Input\n",
      "4\n",
      "torch.Size([3068, 256])\n",
      "torch.Size([70])\n",
      "None\n",
      "None\n",
      "4\n",
      "torch.Size([3068, 256])\n",
      "torch.Size([70])\n",
      "None\n",
      "None\n",
      "tensor([-2.0149e+00, -6.0361e-01, -1.1960e+00, -2.2865e+00, -4.4859e-01,\n",
      "         7.6630e-01, -8.6979e-02,  2.3454e+00,  1.0890e+00, -3.9619e-01,\n",
      "        -7.1854e-01, -1.1675e+00,  9.4324e-01, -9.8904e-01,  2.3972e-02,\n",
      "         4.3202e-01,  1.1914e+00, -2.0167e+00,  1.3723e+00,  1.7466e-01,\n",
      "         3.8195e-01,  1.5554e+00,  1.3900e+00, -7.5800e-01, -1.0323e+00,\n",
      "        -1.6727e+00,  4.4193e-01, -5.5694e-01,  3.9919e-02, -9.7039e-02,\n",
      "         1.7457e-01, -1.6456e-01, -8.7709e-01, -2.3446e-01,  6.2831e-01,\n",
      "         1.0285e+00,  8.3067e-01,  6.2193e-01, -1.1403e+00, -2.4019e-02,\n",
      "         3.6901e-01,  2.6275e-01,  3.5265e-01,  2.1630e-01,  9.0341e-01,\n",
      "         8.8725e-01,  3.2058e-01, -7.1211e-01,  2.2954e+00,  2.6774e-02,\n",
      "        -2.2447e+00, -1.1399e+00,  7.6512e-01,  1.8569e+00,  1.2089e-01,\n",
      "         7.5122e-01, -9.3958e-01,  7.1224e-01, -1.5108e+00,  1.1801e+00,\n",
      "        -1.8316e+00,  1.5403e+00, -1.5066e+00,  5.2591e-01,  2.1435e+00,\n",
      "        -9.2790e-01, -3.0005e-02,  2.9634e-01, -1.1044e+00, -9.4780e-01,\n",
      "         1.0105e+00, -2.8461e+00,  9.0101e-02, -1.1082e+00,  3.6808e-01,\n",
      "         1.4697e+00, -3.6195e-02, -6.9149e-01,  2.2569e-01, -3.2174e-01,\n",
      "        -1.8702e-01, -1.3632e+00,  7.5785e-01, -9.1680e-01,  1.3965e+00,\n",
      "        -6.1125e-01,  8.3012e-01, -4.8949e-01,  6.4788e-01, -1.5009e-01,\n",
      "         2.2682e-01,  1.2417e-01, -8.5994e-01,  6.6468e-01, -1.4859e-01,\n",
      "         1.5469e+00,  9.2002e-01,  2.3920e+00, -1.8318e-01, -2.3217e-01,\n",
      "        -5.5603e-01, -1.3832e+00, -4.5281e-01,  1.6014e+00, -2.7283e-01,\n",
      "        -5.1491e-01, -2.3016e-01,  1.6936e+00, -1.2845e+00, -9.2509e-01,\n",
      "        -2.2107e-01,  1.2942e+00, -5.2536e-01, -1.3186e+00, -1.5210e+00,\n",
      "         1.3008e+00,  1.6033e-01, -5.9077e-01, -1.4646e-01, -1.2308e-01,\n",
      "        -1.7604e+00,  1.1102e+00,  1.2086e+00, -1.1981e+00,  1.2279e+00,\n",
      "        -1.0074e+00, -2.1430e+00,  1.2831e+00, -7.1660e-01, -4.8087e-01,\n",
      "         1.9538e+00,  1.9392e-01, -1.4361e-01, -8.7462e-01, -2.1184e-01,\n",
      "        -1.7307e+00,  8.5380e-01, -6.1095e-01,  1.7459e+00,  1.2664e+00,\n",
      "        -9.8319e-01, -1.2156e-01,  1.7389e-02, -1.5421e-01, -2.7973e-01,\n",
      "        -6.6346e-01, -2.3316e+00, -3.5619e-01,  8.2130e-01, -3.3915e-01,\n",
      "        -1.2736e+00,  8.3157e-01,  3.6249e-02,  1.2710e+00, -1.0853e+00,\n",
      "         9.3227e-01, -1.5071e+00,  8.2602e-01, -7.5044e-01,  7.9976e-01,\n",
      "        -5.5459e-01,  1.2416e+00, -8.8010e-01, -1.3623e-01, -1.3494e+00,\n",
      "        -9.5741e-01, -1.7106e+00, -1.5598e+00, -2.2177e-01, -1.7944e+00,\n",
      "        -8.6183e-01,  4.5885e-01,  1.2262e+00,  9.0597e-01,  6.4744e-01,\n",
      "        -9.2182e-01, -1.0907e+00,  5.8810e-01,  1.8058e-01, -1.5875e+00,\n",
      "         1.9433e+00,  1.2445e+00, -1.1115e+00,  1.2212e+00,  4.4815e-02,\n",
      "         4.6603e-01,  1.6024e-01,  1.5793e+00,  1.2924e+00,  1.7668e+00,\n",
      "        -1.3111e+00, -1.5918e+00,  6.9572e-01, -9.1478e-02, -1.0374e+00,\n",
      "         1.6585e+00,  8.0375e-01, -4.2236e-01, -2.2884e+00,  2.2564e+00,\n",
      "         1.4398e+00,  1.3968e+00,  1.6752e+00, -5.9030e-02,  1.4620e+00,\n",
      "         1.9537e+00, -5.9194e-01,  5.0903e-01, -1.6322e+00,  1.2806e+00,\n",
      "         7.9420e-01, -1.4277e+00,  1.0079e+00,  3.6794e-02, -1.8567e-01,\n",
      "        -3.2979e-01,  7.8281e-01, -1.3028e+00,  2.3227e-01,  6.9078e-01,\n",
      "        -6.6106e-01, -6.9559e-01,  1.0006e-01, -1.8608e+00,  1.0076e+00,\n",
      "         2.4342e-01,  1.0393e+00, -1.6966e-01,  6.6070e-01,  4.6056e-01,\n",
      "         1.7137e+00,  2.7296e-03, -1.1145e+00, -2.3437e-01, -1.5191e+00,\n",
      "        -2.4967e-01,  1.5529e-01, -5.8548e-01, -2.0581e+00,  1.1170e+00,\n",
      "         1.5967e+00,  1.6671e-01, -7.4083e-01,  2.9960e-01,  1.4641e+00,\n",
      "         7.1391e-01,  3.9289e-01,  7.2375e-01, -2.6147e-01, -1.1694e+00,\n",
      "         1.4020e+00,  3.4907e-01,  8.1614e-01, -1.4554e+00,  8.6820e-01,\n",
      "        -2.1470e-02], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor(64)\n",
      "tensor([-0.0145,  0.0098,  0.0017, -0.0072,  0.0091, -0.0145,  0.0085,  0.0077,\n",
      "        -0.0254,  0.0006, -0.0180, -0.0183, -0.0043, -0.0226, -0.0051,  0.0192,\n",
      "         0.0268, -0.0136, -0.0271, -0.0064, -0.0008,  0.0013, -0.0259, -0.0047,\n",
      "        -0.0055, -0.0057,  0.0015,  0.0314,  0.0086,  0.0207, -0.0027, -0.0046,\n",
      "         0.0119, -0.0009, -0.0053,  0.0132,  0.0199, -0.0008,  0.0173, -0.0065,\n",
      "         0.0012,  0.0058,  0.0144, -0.0067, -0.0128, -0.0277,  0.0089, -0.0075,\n",
      "         0.0053, -0.0019, -0.0082,  0.0029,  0.0131,  0.0075, -0.0081,  0.0170,\n",
      "         0.0028,  0.0035,  0.0217, -0.0002, -0.0121, -0.0014, -0.0040, -0.0195,\n",
      "        -0.0073, -0.0043, -0.0186, -0.0169,  0.0057,  0.0061,  0.0009,  0.0103,\n",
      "        -0.0116, -0.0180,  0.0067,  0.0063,  0.0110, -0.0251,  0.0108, -0.0030,\n",
      "        -0.0097,  0.0067, -0.0009, -0.0193, -0.0023,  0.0178, -0.0046, -0.0024,\n",
      "        -0.0077, -0.0020, -0.0165, -0.0001, -0.0146, -0.0067, -0.0195,  0.0151,\n",
      "         0.0067,  0.0055, -0.0046,  0.0166,  0.0138, -0.0186,  0.0159,  0.0055,\n",
      "        -0.0063, -0.0135,  0.0031, -0.0004,  0.0360,  0.0111,  0.0070, -0.0100,\n",
      "        -0.0053, -0.0141, -0.0053, -0.0075, -0.0121,  0.0102,  0.0062, -0.0197,\n",
      "         0.0146, -0.0081,  0.0095, -0.0078,  0.0125, -0.0117, -0.0019,  0.0007,\n",
      "        -0.0076, -0.0169,  0.0017, -0.0194,  0.0171,  0.0116,  0.0021,  0.0086,\n",
      "        -0.0054, -0.0068,  0.0289, -0.0005,  0.0008, -0.0036,  0.0017, -0.0070,\n",
      "         0.0194,  0.0122, -0.0151, -0.0018,  0.0049, -0.0034,  0.0129, -0.0104,\n",
      "         0.0117, -0.0178, -0.0252, -0.0135, -0.0132,  0.0127,  0.0220,  0.0275,\n",
      "         0.0031, -0.0158,  0.0075,  0.0183, -0.0103, -0.0154,  0.0236, -0.0076,\n",
      "        -0.0225,  0.0126,  0.0005,  0.0002, -0.0090, -0.0160, -0.0050,  0.0278,\n",
      "        -0.0152,  0.0209, -0.0105, -0.0009,  0.0030,  0.0155,  0.0079, -0.0050,\n",
      "        -0.0077,  0.0110, -0.0185,  0.0121,  0.0129, -0.0014, -0.0075, -0.0120,\n",
      "         0.0124, -0.0069, -0.0012,  0.0082,  0.0090, -0.0108,  0.0027,  0.0044,\n",
      "         0.0173,  0.0321, -0.0177,  0.0270,  0.0097,  0.0062,  0.0075,  0.0154,\n",
      "        -0.0195,  0.0136,  0.0210,  0.0143,  0.0005,  0.0294, -0.0090, -0.0197,\n",
      "         0.0076, -0.0081,  0.0078, -0.0132, -0.0063,  0.0116,  0.0130, -0.0036,\n",
      "        -0.0085, -0.0041, -0.0215, -0.0139, -0.0253, -0.0089, -0.0024,  0.0002,\n",
      "         0.0213, -0.0226,  0.0030, -0.0027, -0.0184,  0.0061, -0.0118,  0.0041,\n",
      "        -0.0128,  0.0237, -0.0047, -0.0148,  0.0060,  0.0233, -0.0077,  0.0010,\n",
      "        -0.0147,  0.0120, -0.0068, -0.0101,  0.0048,  0.0008,  0.0051, -0.0020],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor(64)\n",
      "output pad packed\n",
      "torch.Size([70, 64, 256])\n",
      "torch.Size([3068, 256])\n",
      "torch.Size([3068, 84])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 84\n",
    "embed_size = 256\n",
    "\n",
    "embedding = nn.Embedding(vocab_size,embed_size)\n",
    "embedding.to(DEVICE)\n",
    "\n",
    "split = 100000\n",
    "train_dataset = LinesDataset(shakespeare_lines[:split])\n",
    "\n",
    "print(train_dataset)\n",
    "\n",
    "\n",
    "##train_data_flat\n",
    "##train_labels_flat\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64, collate_fn = collate_lines)\n",
    "\n",
    "i = 0\n",
    "for inputs,targets in train_loader:\n",
    "    print(inputs[0].size())\n",
    "    \n",
    "    seq_list = inputs\n",
    "    \n",
    "    batch_size = len(seq_list)\n",
    "    print(\"Batchsize\")\n",
    "    print(batch_size)\n",
    "    \n",
    "    lens = [len(s) for s in seq_list] # lens of all lines (already sorted)\n",
    "    print(\"lens\")\n",
    "    print(lens)\n",
    "    print(sum(lens))\n",
    "    bounds = [0]\n",
    "    for l in lens:\n",
    "        bounds.append(bounds[-1]+l) # bounds of all lines in the concatenated sequence. Indexing into the list to \n",
    "        ##print(l)\n",
    "        ##print(bounds[-1])  # see where the sequence occurs. Need this at line marked **\n",
    "        \n",
    "    print(len(seq_list))\n",
    "    print(seq_list[0].size())\n",
    "    seq_concat = torch.cat(seq_list) # concatenated sequence\n",
    "    print(\"seq_concat\")\n",
    "    print(seq_concat.size())\n",
    "    print(seq_concat[0:20])\n",
    "    embed_concat = embedding(seq_concat) # concatenated embeddings\n",
    "    \n",
    "    print(\"Embedd output\")\n",
    "    print(embed_concat.size())\n",
    "    print(embed_concat[0,:])\n",
    "    \n",
    "    embed_list = [embed_concat[bounds[i]:bounds[i+1]] for i in range(batch_size)]\n",
    "    \n",
    "    print(\"Embedd List\")\n",
    "    print(embed_concat.size())\n",
    "    print(len(embed_list))\n",
    "    print(embed_list[0].size())\n",
    "    packed_input = rnn.pack_sequence(embed_list)\n",
    "    \n",
    "    \n",
    "    print(\"Packed Input\")\n",
    "    print(len(packed_input))\n",
    "    \n",
    "    print(packed_input[0].size())\n",
    "    print(packed_input[1].size())\n",
    "    print(packed_input[2])\n",
    "    print(packed_input[3])\n",
    "    \n",
    "    \n",
    "    hidden = None\n",
    "    \n",
    "    rnn_x = nn.LSTM(input_size = embed_size,hidden_size=256,num_layers=3)\n",
    "    rnn_x.to(DEVICE)\n",
    "    output_packed,hidden = rnn_x(packed_input,hidden)\n",
    "    \n",
    "    print(len(output_packed))\n",
    "    print(output_packed[0].size())\n",
    "    print(output_packed[1].size())\n",
    "    print(output_packed[2])\n",
    "    print(output_packed[3])\n",
    "    \n",
    "    print(packed_input[0][0,:])\n",
    "    print(packed_input[1][2])\n",
    "    \n",
    "    print(output_packed[0][0,:])\n",
    "    print(output_packed[1][2])\n",
    "    \n",
    "    \n",
    "    output_padded, _ = rnn.pad_packed_sequence(output_packed)\n",
    "    \n",
    "    print(\"output pad packed\")\n",
    "    print(output_padded.size())\n",
    "    \n",
    "    output_flatten = torch.cat([output_padded[:lens[i],i] for i in range(batch_size)])\n",
    "    \n",
    "    print(output_flatten.size())\n",
    "    \n",
    "    scoring = nn.Linear(256,vocab_size)\n",
    "    \n",
    "    scoring.to(DEVICE)\n",
    "    \n",
    "    scores_flatten = scoring(output_flatten)\n",
    "    \n",
    "    print(scores_flatten.size())\n",
    "    \n",
    "    \n",
    "    \n",
    "    i = i + 1\n",
    "    if i == 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 84\n",
    "embed_size = 256\n",
    "\n",
    "embedding = nn.Embedding(vocab_size,embed_size)\n",
    "embedding.to(DEVICE)\n",
    "\n",
    "##split = 100000\n",
    "##train_dataset = LinesDataset(shakespeare_lines[:split])\n",
    "\n",
    "##print(train_dataset)\n",
    "\n",
    "\n",
    "train_data_flat\n",
    "train_labels_flat\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64, collate_fn = collate_lines)\n",
    "\n",
    "i = 0\n",
    "for inputs,targets in train_loader:\n",
    "    print(inputs[0].size())\n",
    "    \n",
    "    seq_list = inputs\n",
    "    \n",
    "    batch_size = len(seq_list)\n",
    "    print(\"Batchsize\")\n",
    "    print(batch_size)\n",
    "    \n",
    "    lens = [len(s) for s in seq_list] # lens of all lines (already sorted)\n",
    "    print(\"lens\")\n",
    "    print(lens)\n",
    "    print(sum(lens))\n",
    "    bounds = [0]\n",
    "    for l in lens:\n",
    "        bounds.append(bounds[-1]+l) # bounds of all lines in the concatenated sequence. Indexing into the list to \n",
    "        ##print(l)\n",
    "        ##print(bounds[-1])  # see where the sequence occurs. Need this at line marked **\n",
    "        \n",
    "    print(len(seq_list))\n",
    "    print(seq_list[0].size())\n",
    "    seq_concat = torch.cat(seq_list) # concatenated sequence\n",
    "    print(seq_concat.size())\n",
    "    print(seq_concat[0:20])\n",
    "    embed_concat = embedding(seq_concat) # concatenated embeddings\n",
    "    print(embed_concat.size())\n",
    "    print(embed_concat[0,:])\n",
    "    \n",
    "    embed_list = [embed_concat[bounds[i]:bounds[i+1]] for i in range(batch_size)]\n",
    "    print(len(embed_list))\n",
    "    print(embed_list[0].size())\n",
    "    packed_input = rnn.pack_sequence(embed_list)\n",
    "    print(len(packed_input))\n",
    "    \n",
    "    print(packed_input[0].size())\n",
    "    print(packed_input[1].size())\n",
    "    print(packed_input[2])\n",
    "    print(packed_input[3])\n",
    "    \n",
    "    \n",
    "    hidden = None\n",
    "    \n",
    "    rnn_x = nn.LSTM(input_size = embed_size,hidden_size=256,num_layers=3)\n",
    "    rnn_x.to(DEVICE)\n",
    "    output_packed,hidden = rnn_x(packed_input,hidden)\n",
    "    \n",
    "    print(len(output_packed))\n",
    "    print(output_packed[0].size())\n",
    "    print(output_packed[1].size())\n",
    "    print(output_packed[2])\n",
    "    print(output_packed[3])\n",
    "    \n",
    "    print(packed_input[0][0,:])\n",
    "    print(packed_input[1][2])\n",
    "    \n",
    "    print(output_packed[0][0,:])\n",
    "    print(output_packed[1][2])\n",
    "    \n",
    "    \n",
    "    output_padded, _ = rnn.pad_packed_sequence(output_packed)\n",
    "    print(output_padded.size())\n",
    "    \n",
    "    output_flatten = torch.cat([output_padded[:lens[i],i] for i in range(batch_size)])\n",
    "    \n",
    "    print(output_flatten.size())\n",
    "    \n",
    "    scoring = nn.Linear(256,vocab_size)\n",
    "    \n",
    "    scoring.to(DEVICE)\n",
    "    \n",
    "    scores_flatten = scoring(output_flatten)\n",
    "    \n",
    "    print(scores_flatten.size())\n",
    "    \n",
    "    \n",
    "    \n",
    "    i = i + 1\n",
    "    if i == 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cg8ln5cG50nW"
   },
   "outputs": [],
   "source": [
    "# Model that takes packed sequences in training\n",
    "class PackedLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embed_size,hidden_size, nlayers, stop):\n",
    "        super(PackedLanguageModel,self).__init__()\n",
    "        self.vocab_size=vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.nlayers=nlayers\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_size)\n",
    "        self.rnn = nn.LSTM(input_size = embed_size,hidden_size=hidden_size,num_layers=nlayers) # 1 layer, batch_size = False\n",
    "        self.scoring = nn.Linear(hidden_size,vocab_size)\n",
    "        self.stop = stop # stop line character (\\n)\n",
    "    \n",
    "    def forward(self,seq_list): # list\n",
    "        batch_size = len(seq_list)\n",
    "        lens = [len(s) for s in seq_list] # lens of all lines (already sorted)\n",
    "        bounds = [0]\n",
    "        for l in lens:\n",
    "            bounds.append(bounds[-1]+l) # bounds of all lines in the concatenated sequence. Indexing into the list to \n",
    "                                        # see where the sequence occurs. Need this at line marked **\n",
    "        seq_concat = torch.cat(seq_list) # concatenated sequence\n",
    "        embed_concat = self.embedding(seq_concat) # concatenated embeddings\n",
    "        embed_list = [embed_concat[bounds[i]:bounds[i+1]] for i in range(batch_size)] # embeddings per line **\n",
    "        packed_input = rnn.pack_sequence(embed_list) # packed version\n",
    "        \n",
    "        # alternatively, you could use rnn.pad_sequence, followed by rnn.pack_padded_sequence\n",
    "        \n",
    "        \n",
    "        \n",
    "        hidden = None\n",
    "        output_packed,hidden = self.rnn(packed_input,hidden)\n",
    "        output_padded, _ = rnn.pad_packed_sequence(output_packed) # unpacked output (padded). Also gives you the lengths\n",
    "        output_flatten = torch.cat([output_padded[:lens[i],i] for i in range(batch_size)]) # concatenated output\n",
    "        scores_flatten = self.scoring(output_flatten) # concatenated logits\n",
    "        return scores_flatten # return concatenated logits\n",
    "    \n",
    "    def generate(self,seq, n_words): # L x V\n",
    "        generated_words = []\n",
    "        embed = self.embedding(seq).unsqueeze(1) # L x 1 x E\n",
    "        ##hidden = None\n",
    "        output_lstm, hidden = self.rnn(embed)[0] # L x 1 x H\n",
    "        output = output_lstm[-1] # 1 x H\n",
    "        scores = self.scoring(output) # 1 x V\n",
    "        _,current_word = torch.max(scores,dim=1) # 1 x 1\n",
    "        generated_words.append(current_word)\n",
    "        if n_words > 1:\n",
    "            for i in range(n_words-1):\n",
    "                embed = self.embedding(current_word).unsqueeze(0) # 1 x 1 x E\n",
    "                output_lstm, hidden = self.rnn(embed,hidden) # 1 x 1 x H\n",
    "                output = output_lstm[0] # 1 x H\n",
    "                scores = self.scoring(output) # V\n",
    "                _,current_word = torch.max(scores,dim=1) # 1\n",
    "                generated_words.append(current_word)\n",
    "                if current_word[0].item()==self.stop: # If end of line\n",
    "                    break\n",
    "        return torch.cat(generated_words,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vx3G8mc50nY"
   },
   "outputs": [],
   "source": [
    "def train_epoch_packed(model, optimizer, train_loader, val_loader):\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"sum\") # sum instead of averaging, to take into account the different lengths\n",
    "    criterion = criterion.to(DEVICE)\n",
    "    batch_id=0\n",
    "    before = time.time()\n",
    "    print(\"Training\", len(train_loader), \"number of batches\")\n",
    "    for inputs,targets in train_loader: # lists, presorted, preloaded on GPU\n",
    "        batch_id+=1\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,torch.cat(targets)) # criterion of the concatenated output\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_id % 100 == 0:\n",
    "            after = time.time()\n",
    "            nwords = np.sum(np.array([len(l) for l in inputs]))\n",
    "            lpw = loss.item() / nwords\n",
    "            print(\"Time elapsed: \", after - before)\n",
    "            print(\"At batch\",batch_id)\n",
    "            print(\"Training loss per word:\",lpw)\n",
    "            print(\"Training perplexity :\",np.exp(lpw))\n",
    "            before = after\n",
    "    \n",
    "    val_loss = 0\n",
    "    batch_id=0\n",
    "    nwords = 0\n",
    "    for inputs,targets in val_loader:\n",
    "        nwords += np.sum(np.array([len(l) for l in inputs]))\n",
    "        batch_id+=1\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,torch.cat(targets))\n",
    "        val_loss+=loss.item()\n",
    "    val_lpw = val_loss / nwords\n",
    "    print(\"\\nValidation loss per word:\",val_lpw)\n",
    "    print(\"Validation perplexity :\",np.exp(val_lpw),\"\\n\")\n",
    "    return val_lpw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFvvuete50na"
   },
   "outputs": [],
   "source": [
    "model = PackedLanguageModel(charcount,256,256,3, stop=stop_character)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001, weight_decay=1e-6)\n",
    "split = 100000\n",
    "train_dataset = LinesDataset(shakespeare_lines[:split])\n",
    "val_dataset = LinesDataset(shakespeare_lines[split:])\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64, collate_fn = collate_lines)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=64, collate_fn = collate_lines, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4SFfNTCL50nb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1563 number of batches\n",
      "Time elapsed:  4.3084876537323\n",
      "At batch 100\n",
      "Training loss per word: 2.8123067679753064\n",
      "Training perplexity : 16.64827767237601\n",
      "Time elapsed:  4.242072105407715\n",
      "At batch 200\n",
      "Training loss per word: 2.221636252428489\n",
      "Training perplexity : 9.222408715591532\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-10a6dee54bf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_epoch_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-607c25ff449c>\u001b[0m in \u001b[0;36mtrain_epoch_packed\u001b[0;34m(model, optimizer, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# criterion of the concatenated output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_id\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_epoch_packed(model, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oz9Kg1p650nd"
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"trained_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VHp8x3l650ng"
   },
   "outputs": [],
   "source": [
    "print(generate(model, \"To be, or not to be, that is the q\",20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ig5Y50kJ50ni"
   },
   "outputs": [],
   "source": [
    "print(generate(model, \"Richard \", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8mMJwLSd50nm"
   },
   "outputs": [],
   "source": [
    "print(generate(model, \"Hello\", 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8woC85Ud50np"
   },
   "source": [
    "### Reminders\n",
    "\n",
    "By default, for all rnn modules (rnn, GRU, LSTM) batch_first = False\n",
    "To use packed sequences, your inputs first need to be sorted in descending order of length (longest to shortest)\n",
    "Batches need to have inputs of the same length "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6sGgg7K50nq"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "language_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
